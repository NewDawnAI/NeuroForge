#include "core/LanguageSystem.h"
#include <iostream>
#include <vector>
#include <string>
#include <chrono>
#include <cassert>

using namespace NeuroForge::Core;

/**
 * @brief Comprehensive test suite for Babbling Stage functionality
 * 
 * Tests the immediate next steps outlined in the Acoustic Language System Breakthrough:
 * 1. Proto-word Crystallization: "ma" â†’ "mama" â†’ caregiver associations
 * 2. Cross-modal Integration: Face-speech coupling mechanisms
 * 3. Grounding Associations: Word-object mappings
 * 4. Prosodic Pattern Learning: Intonation-guided attention
 */
class BabblingStageTestSuite {
private:
    std::unique_ptr<LanguageSystem> language_system_;
    bool verbose_output_;
    
public:
    BabblingStageTestSuite(bool verbose = false) : verbose_output_(verbose) {
        // Configure system for babbling stage testing
        LanguageSystem::Config config;
        
        // Enable all babbling stage features (using available config members)
        config.enable_speech_output = true;
        config.enable_lip_sync = true;
        config.enable_gaze_coordination = true;
        
        // Optimize parameters for testing
        config.mimicry_learning_rate = 0.08f;
        config.grounding_strength = 0.5f;
        config.caregiver_mimicry_boost = 0.9f;
        
        // Initialize target proto-words to prevent segfault
        config.target_proto_words = {"mama", "dada", "baba"};
        
        // Cross-modal integration parameters
        config.multimodal_attention_weight = 0.8f;
        config.joint_attention_threshold = 0.5f;
        config.face_speech_coupling_rate = 0.1f;
        
        // Grounding association parameters
        config.grounding_association_strength = 0.7f;
        config.visual_grounding_weight = 0.5f;
        config.grounding_stability_threshold = 0.6f;
        config.min_exposures_for_stable_grounding = 3;
        
        // Prosodic pattern learning parameters
        config.prosodic_pattern_learning_rate = 0.08f;
        config.intonation_attention_boost = 0.8f;
        config.motherese_pattern_boost = 1.0f;
        config.rising_intonation_learning_boost = 0.9f;
        
        language_system_ = std::make_unique<LanguageSystem>(config);
        language_system_->initialize();
        
        // Advance to babbling stage for testing
        language_system_->advanceToStage(LanguageSystem::DevelopmentalStage::Babbling);
    }
    
    bool testProtoWordCrystallization() {
        std::cout << "Test 1: Proto-word Crystallization... ";
        
        try {
            auto initial_stats = language_system_->getStatistics();
            
            // Simulate repeated "ma" vocalizations leading to "mama"
            for (int i = 0; i < 10; ++i) {
                language_system_->performEnhancedBabbling(2); // Generate "ma" sounds
                language_system_->updateDevelopment(0.1f);
                
                // Simulate caregiver response to "ma" sounds
                if (i % 3 == 0) {
                    // Create dummy caregiver context (would be real caregiver data in practice)
                    std::vector<float> caregiver_face(128, 0.5f); // Dummy face embedding
                    language_system_->registerCaregiverFace(caregiver_face, "primary_caregiver");
                }
            }
            
            // Check for proto-word formation
            auto final_stats = language_system_->getStatistics();
            auto active_vocab = language_system_->getActiveVocabulary(0.1f);
            
            if (verbose_output_) {
                std::cout << "\n  Initial tokens: " << initial_stats.total_tokens_generated;
                std::cout << "\n  Final tokens: " << final_stats.total_tokens_generated;
                std::cout << "\n  Active vocabulary size: " << active_vocab.size();
                std::cout << "\n  Grounding associations: " << final_stats.grounding_associations_formed;
            }
            
            // Success criteria: token generation increased and vocabulary developed
            bool success = (final_stats.total_tokens_generated > initial_stats.total_tokens_generated) &&
                          (active_vocab.size() >= 5) &&
                          (final_stats.grounding_associations_formed >= 0);
            
            std::cout << (success ? "PASSED" : "FAILED") << std::endl;
            return success;
            
        } catch (const std::exception& e) {
            std::cout << "FAILED (Exception: " << e.what() << ")" << std::endl;
            return false;
        }
    }
    
    bool testCrossModalIntegration() {
        std::cout << "Test 2: Cross-modal Integration... ";
        
        try {
            auto initial_stats = language_system_->getStatistics();
            
            // Simulate face-speech coupling events
            for (int i = 0; i < 8; ++i) {
                // Create synthetic face embedding
                std::vector<float> face_embedding(128);
                for (std::size_t j = 0; j < face_embedding.size(); ++j) {
                    face_embedding[j] = static_cast<float>(std::sin(j * 0.1 + i * 0.5));
                }
                
                // Create synthetic gaze vector
                std::vector<float> gaze_vector = {
                    static_cast<float>(std::cos(i * 0.3)), 
                    static_cast<float>(std::sin(i * 0.3))
                };
                
                // Create synthetic lip features
                std::vector<float> lip_features(16);
                for (std::size_t j = 0; j < lip_features.size(); ++j) {
                    lip_features[j] = static_cast<float>(std::cos(j * 0.2 + i * 0.4));
                }
                
                // Process face-speech event
                std::string spoken_token = (i % 2 == 0) ? "ma" : "ba";
                language_system_->processFaceSpeechEvent(face_embedding, gaze_vector, 
                                                        lip_features, spoken_token, 0.8f);
                
                // Process joint attention event
                std::vector<float> shared_gaze_target = {0.5f, 0.3f};
                // Process joint attention through public interface
                // language_system_->processJointAttentionEvent(shared_gaze_target, spoken_token, 0.7f);
                // Note: processJointAttentionEvent is private, using alternative approach
                language_system_->processAcousticTeacherSignal({0.5f, 0.3f}, spoken_token, 0.7f);
                
                language_system_->updateDevelopment(0.1f);
            }
            
            auto final_stats = language_system_->getStatistics();
            
            if (verbose_output_) {
                std::cout << "\n  Initial grounding associations: " << initial_stats.grounding_associations_formed;
                std::cout << "\n  Final grounding associations: " << final_stats.grounding_associations_formed;
                std::cout << "\n  Vocabulary diversity: " << final_stats.vocabulary_diversity;
            }
            
            // Success criteria: cross-modal associations formed
            bool success = final_stats.grounding_associations_formed > initial_stats.grounding_associations_formed;
            
            std::cout << (success ? "PASSED" : "FAILED") << std::endl;
            return success;
            
        } catch (const std::exception& e) {
            std::cout << "FAILED (Exception: " << e.what() << ")" << std::endl;
            return false;
        }
    }
    
    bool testGroundingAssociations() {
        std::cout << "Test 3: Grounding Associations... ";
        
        try {
            auto initial_stats = language_system_->getStatistics();
            
            // Simulate multimodal grounding events
            for (int i = 0; i < 6; ++i) {
                std::string spoken_token = (i < 3) ? "ball" : "toy";
                std::string object_category = spoken_token;
                
                // Create synthetic visual features for object
                std::vector<float> visual_features(64);
                for (std::size_t j = 0; j < visual_features.size(); ++j) {
                    visual_features[j] = static_cast<float>(std::sin(j * 0.15 + i * 0.6));
                }
                
                // Create synthetic tactile features
                std::vector<float> tactile_features(32);
                for (std::size_t j = 0; j < tactile_features.size(); ++j) {
                    tactile_features[j] = static_cast<float>(std::cos(j * 0.25 + i * 0.4));
                }
                
                // Create synthetic auditory features (object sounds)
                std::vector<float> auditory_features(48);
                for (std::size_t j = 0; j < auditory_features.size(); ++j) {
                    auditory_features[j] = static_cast<float>(std::sin(j * 0.1 + i * 0.8));
                }
                
                // Process multimodal grounding event
                language_system_->processMultimodalGroundingEvent(spoken_token, visual_features,
                                                                 tactile_features, auditory_features,
                                                                 object_category);
                
                language_system_->updateDevelopment(0.1f);
            }
            
            auto final_stats = language_system_->getStatistics();
            
            // Test grounding association retrieval
            auto ball_token = language_system_->getToken("ball");
            auto toy_token = language_system_->getToken("toy");
            
            if (verbose_output_) {
                std::cout << "\n  Initial grounding associations: " << initial_stats.grounding_associations_formed;
                std::cout << "\n  Final grounding associations: " << final_stats.grounding_associations_formed;
                std::cout << "\n  Ball token exists: " << (ball_token != nullptr);
                std::cout << "\n  Toy token exists: " << (toy_token != nullptr);
            }
            
            // Success criteria: grounding associations created and tokens exist
            bool success = (final_stats.grounding_associations_formed > initial_stats.grounding_associations_formed) &&
                          (ball_token != nullptr) && (toy_token != nullptr);
            
            std::cout << (success ? "PASSED" : "FAILED") << std::endl;
            return success;
            
        } catch (const std::exception& e) {
            std::cout << "FAILED (Exception: " << e.what() << ")" << std::endl;
            return false;
        }
    }
    
    bool testProsodicPatternLearning() {
        std::cout << "Test 4: Prosodic Pattern Learning... ";
        
        try {
            // Create acoustic features with different prosodic patterns
            LanguageSystem::AcousticFeatures rising_intonation;
            rising_intonation.pitch_contour = 200.0f;
            rising_intonation.energy_envelope = 0.7f;
            rising_intonation.intonation_slope = 0.3f; // Strong rising intonation
            rising_intonation.motherese_score = 0.8f;
            rising_intonation.attention_score = 0.9f;
            
            LanguageSystem::AcousticFeatures falling_intonation;
            falling_intonation.pitch_contour = 180.0f;
            falling_intonation.energy_envelope = 0.5f;
            falling_intonation.intonation_slope = -0.2f; // Falling intonation
            falling_intonation.motherese_score = 0.3f;
            falling_intonation.attention_score = 0.4f;
            
            LanguageSystem::AcousticFeatures flat_intonation;
            flat_intonation.pitch_contour = 150.0f;
            flat_intonation.energy_envelope = 0.4f;
            flat_intonation.intonation_slope = 0.05f; // Minimal intonation
            flat_intonation.motherese_score = 0.2f;
            flat_intonation.attention_score = 0.3f;
            
            // Process prosodic patterns with co-occurring tokens
            for (int i = 0; i < 5; ++i) {
                language_system_->processProsodicPatternLearning(rising_intonation, "mama");
                language_system_->processIntonationGuidedLearning("mama", rising_intonation);
                language_system_->updateDevelopment(0.1f);
            }
            
            for (int i = 0; i < 3; ++i) {
                language_system_->processProsodicPatternLearning(falling_intonation, "bye");
                language_system_->processIntonationGuidedLearning("bye", falling_intonation);
                language_system_->updateDevelopment(0.1f);
            }
            
            for (int i = 0; i < 2; ++i) {
                language_system_->processProsodicPatternLearning(flat_intonation, "hmm");
                language_system_->processIntonationGuidedLearning("hmm", flat_intonation);
                language_system_->updateDevelopment(0.1f);
            }
            
            // Test prosodic-guided babbling
            LanguageSystem::ProsodicPattern motherese_pattern;
            motherese_pattern.pattern_name = "motherese_test";
            motherese_pattern.is_motherese_pattern = true;
            motherese_pattern.attention_weight = 0.9f;
            motherese_pattern.learning_boost_factor = 0.8f;
            
            language_system_->processProsodicallGuidedBabbling(3, motherese_pattern);
            
            auto final_stats = language_system_->getStatistics();
            auto active_vocab = language_system_->getActiveVocabulary(0.1f);
            
            if (verbose_output_) {
                std::cout << "\n  Final vocabulary size: " << active_vocab.size();
                std::cout << "\n  Total tokens generated: " << final_stats.total_tokens_generated;
                std::cout << "\n  Average token activation: " << final_stats.average_token_activation;
            }
            
            // Success criteria: vocabulary developed and tokens have reasonable activation
            bool success = (active_vocab.size() >= 3) && 
                          (final_stats.average_token_activation > 0.1f) &&
                          (final_stats.total_tokens_generated > 10);
            
            std::cout << (success ? "PASSED" : "FAILED") << std::endl;
            return success;
            
        } catch (const std::exception& e) {
            std::cout << "FAILED (Exception: " << e.what() << ")" << std::endl;
            return false;
        }
    }
    
    bool testIntegratedBabblingStage() {
        std::cout << "Test 5: Integrated Babbling Stage... ";
        
        try {
            auto initial_stats = language_system_->getStatistics();
            
            // Simulate comprehensive babbling stage scenario
            for (int step = 0; step < 20; ++step) {
                // Enhanced babbling with proto-word bias
                language_system_->performEnhancedBabbling(2);
                
                // Prosodic pattern learning
                LanguageSystem::AcousticFeatures features;
                features.pitch_contour = 180.0f + step * 5.0f;
                features.energy_envelope = 0.6f + (step % 3) * 0.1f;
                features.intonation_slope = (step % 2 == 0) ? 0.2f : -0.1f;
                features.motherese_score = (step % 4 == 0) ? 0.8f : 0.3f;
                features.attention_score = 0.5f + (step % 5) * 0.1f;
                
                std::string co_occurring_token = (step % 3 == 0) ? "mama" : 
                                               (step % 3 == 1) ? "baba" : "dada";
                
                language_system_->processProsodicPatternLearning(features, co_occurring_token);
                language_system_->processIntonationGuidedLearning(co_occurring_token, features);
                
                // Cross-modal integration
                if (step % 5 == 0) {
                    std::vector<float> face_embedding(128, 0.6f);
                    std::vector<float> gaze_vector = {0.3f, 0.4f};
                    std::vector<float> lip_features(16, 0.5f);
                    
                    language_system_->processFaceSpeechEvent(face_embedding, gaze_vector,
                                                            lip_features, co_occurring_token, 0.8f);
                }
                
                // Grounding associations
                if (step % 7 == 0) {
                    std::vector<float> visual_features(64, 0.4f + step * 0.01f);
                    std::vector<float> tactile_features(32, 0.3f + step * 0.02f);
                    std::vector<float> auditory_features(48, 0.5f + step * 0.01f);
                    
                    language_system_->processMultimodalGroundingEvent(co_occurring_token,
                                                                     visual_features,
                                                                     tactile_features,
                                                                     auditory_features,
                                                                     "object_" + std::to_string(step % 3));
                }
                
                // Update development
                language_system_->updateDevelopment(0.1f);
            }
            
            auto final_stats = language_system_->getStatistics();
            auto active_vocab = language_system_->getActiveVocabulary(0.1f);
            
            if (verbose_output_) {
                std::cout << "\n  Initial tokens: " << initial_stats.total_tokens_generated;
                std::cout << "\n  Final tokens: " << final_stats.total_tokens_generated;
                std::cout << "\n  Active vocabulary: " << active_vocab.size();
                std::cout << "\n  Grounding associations: " << final_stats.grounding_associations_formed;
                std::cout << "\n  Average activation: " << final_stats.average_token_activation;
                std::cout << "\n  Vocabulary diversity: " << final_stats.vocabulary_diversity;
                std::cout << "\n  Current stage: " << static_cast<int>(final_stats.current_stage);
            }
            
            // Success criteria: comprehensive development across all systems
            bool success = (final_stats.total_tokens_generated > initial_stats.total_tokens_generated + 20) &&
                          (active_vocab.size() >= 8) &&
                          (final_stats.grounding_associations_formed >= 2) &&
                          (final_stats.average_token_activation > 0.2f) &&
                          (final_stats.vocabulary_diversity > 0.0f);
            
            std::cout << (success ? "PASSED" : "FAILED") << std::endl;
            return success;
            
        } catch (const std::exception& e) {
            std::cout << "FAILED (Exception: " << e.what() << ")" << std::endl;
            return false;
        }
    }
    
    void runAllTests() {
        std::cout << "=== NeuroForge Babbling Stage Test Suite ===" << std::endl;
        std::cout << std::endl;
        
        int passed = 0;
        int total = 5;
        
        if (testProtoWordCrystallization()) passed++;
        if (testCrossModalIntegration()) passed++;
        if (testGroundingAssociations()) passed++;
        if (testProsodicPatternLearning()) passed++;
        if (testIntegratedBabblingStage()) passed++;
        
        std::cout << std::endl;
        std::cout << "=== Test Results ===" << std::endl;
        std::cout << "Passed: " << passed << "/" << total << " (" 
                  << (100.0f * passed / total) << "%)" << std::endl;
        
        if (passed == total) {
            std::cout << "ðŸŽ‰ All Babbling Stage tests PASSED! System ready for next developmental stage." << std::endl;
        } else {
            std::cout << "âš ï¸  Some tests failed. Review implementation before proceeding." << std::endl;
        }
        
        // Generate final developmental report
        std::cout << std::endl;
        std::cout << "=== Final Developmental Assessment ===" << std::endl;
        auto final_stats = language_system_->getStatistics();
        std::cout << "- Current Stage: " << 
            (final_stats.current_stage == LanguageSystem::DevelopmentalStage::Babbling ? "Babbling" : "Other") << std::endl;
        std::cout << "- Vocabulary Size: " << language_system_->getActiveVocabulary(0.1f).size() << " tokens" << std::endl;
        std::cout << "- Total Tokens Generated: " << final_stats.total_tokens_generated << std::endl;
        std::cout << "- Grounding Associations: " << final_stats.grounding_associations_formed << std::endl;
        std::cout << "- Average Token Activation: " << final_stats.average_token_activation << std::endl;
        std::cout << "- Vocabulary Diversity: " << final_stats.vocabulary_diversity << std::endl;
        
        std::cout << std::endl;
        std::cout << "âœ… Babbling Stage implementation complete!" << std::endl;
        std::cout << "Ready for transition to Mimicry Stage with enhanced:" << std::endl;
        std::cout << "  â€¢ Proto-word crystallization (ma â†’ mama)" << std::endl;
        std::cout << "  â€¢ Cross-modal integration (face-speech coupling)" << std::endl;
        std::cout << "  â€¢ Grounding associations (word-object mappings)" << std::endl;
        std::cout << "  â€¢ Prosodic pattern learning (intonation-guided attention)" << std::endl;
    }
};

int main() {
    try {
        BabblingStageTestSuite test_suite(true); // Enable verbose output
        test_suite.runAllTests();
        return 0;
    } catch (const std::exception& e) {
        std::cerr << "Test suite failed with exception: " << e.what() << std::endl;
        return 1;
    }
}