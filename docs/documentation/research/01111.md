NeuroForge Project Status

Summary
- The core hypergraph brain, region scaffolding, connectivity, and the demo application are implemented and run successfully.
- A LearningSystem exists with Hebbian and STDP mechanisms, attention modulation hooks, homeostasis, and consolidation utilities, and can be enabled in the demo via --enable-learning (disabled by default).
- Vision and audio demo modes are available in the app; synthetic inputs are used as fallback when devices are unavailable.
- VisionEncoder and AudioEncoder are implemented, built as a separate static library (neuroforge_encoders), and integrated into the main demo. The demo processes device or synthetic inputs through these encoders before feeding features to cortical regions.
- Synapse snapshot export (CSV) and a live OpenCV-based heatmap viewer have been added for quick visualization and offline analysis.
- NEW: Cap'n Proto export/import (exportToCapnp/importFromCapnp) is fully implemented in HypergraphBrain and verified via unit tests to round-trip brain topology and synapses correctly.
- NEW: Reward and self-model logging APIs are implemented (HypergraphBrain::logReward, HypergraphBrain::logSelfModel) and backed by MemoryDB with passing tests.
- NEW: Lightweight MemoryDB query APIs and CLI flags are available to inspect per-run data: getEpisodes(run_id), getRecentRewards(run_id, limit), and CLI flags --list-episodes, --recent-rewards, and --list-runs.
- NEW: getRuns() API added to MemoryDB for programmatic enumeration of runs; a matching CLI flag --list-runs is available.

Core Brain and Processing
- HypergraphBrain manages regions, global synapses, processing modes (Sequential, Parallel, Hierarchical, Custom), statistics, and hardware monitoring.
- The demo constructs a brain with a ConnectivityManager, creates multiple cortical and subcortical regions, establishes connectivity, initializes patterns, and runs a simulation loop with periodic statistics output.
- Processing frequency and cycle counts are tracked; hardware monitoring support exists and is togglable.

Learning and Plasticity
- LearningSystem implements:
  - Hebbian updates per region, with optional attention-weight modulation and per-synapse learning rates.
  - STDP support at the synapse level; a public onNeuronSpike hook is present for recording spike times.
  - Homeostasis (optional), consolidation with weight decay, attention maps, and statistics collection.
  - Thread-safe, deduplicated synapse snapshot API for visualization/export.
- Integration status:
  - HypergraphBrain exposes initializeLearning, applyHebbianLearning, consolidateMemories, and applyAttentionModulation.
  - The demo (main.cpp) supports enabling learning via --enable-learning and passes LearningSystem::Config (including hebbian_rate, stdp_rate, stdp_rate_multiplier) to brain_->initializeLearning.
  - Spike event wiring into LearningSystem::onNeuronSpike is implemented in HypergraphBrain::initializeLearning via Neuron::setSpikeCallback with timestamps.
  - main.cpp can call LearningSystem::getSynapseSnapshot() for either CSV export (--snapshot-csv) or live heatmap snapshots.

Regions and Connectivity
- Region classes and pointers for primary cortical and subcortical structures are present and used by the demo.
- Connectivity is established between regions with controllable density and weight ranges via HypergraphBrain APIs.

I/O Demos and Encoders
- Vision demo uses OpenCV camera input when enabled; otherwise, synthetic frames are generated.
  - Camera configuration: supports --camera-index for device selection and --camera-backend (msmf/dshow/any) for Windows backend selection.
  - Both Microsoft Media Foundation (msmf) and DirectShow (dshow) backends have been tested and confirmed working.
- Audio demo for Windows uses waveIn APIs; otherwise, synthetic audio is used.
  - Microphone capture: supports --audio-mic=on for real microphone input with configurable --audio-sample-rate.
- Feature extraction layers are formalized via encoders. VisionEncoder supports configurable grid size and edge/intensity weighting. AudioEncoder supports configurable feature bins, spectral bins, Mel bands, and pre-emphasis.

Visualization and Export
- CSV export of synapse snapshots at end of run via --snapshot-csv=PATH (format: pre_neuron,post_neuron,weight).
- Live OpenCV heatmap visualization via --heatmap-view with interval/size/threshold controls; uses modulo bucketing of neuron IDs to form an NxN grid of accumulated |weight|.

Metrics and Monitoring
- Brain-wide statistics (regions, neurons, synapses, activation, energy, frequency) are computed and displayed.
- LearningSystem maintains per-update statistics, which are displayed in the demo when learning is enabled.

Persistence and State
- Cap'n Proto serialization:
  - exportToCapnp/importFromCapnp are implemented for full-fidelity round-trip of brain properties, regions, neurons, and synapses.
  - Uses word-aligned flat arrays and reconstructs via connectNeurons to rebuild inter-region bookkeeping; fine-grained locking avoids deadlocks during import.
  - Verified by passing unit tests for Cap'n Proto round-trip.
- JSON serialization:
  - exportToJson provides a lightweight snapshot of brain topology.
  - importFromJson exists for basic topology restoration; full fidelity (e.g., all learning state) may be limited compared to Cap'n Proto.
- MemoryDB integration:
  - Supports runs and episodes, with insertLearningStats, insertExperience, insertRewardLog, and insertSelfModel.
  - HypergraphBrain exposes setMemoryDB, startEpisode/endEpisode, and the new logReward/logSelfModel helpers using system timestamps and processing steps.
  - Query/readback: getEpisodes(run_id), getRecentRewards(run_id, limit), and getRuns() enable programmatic inspection; CLI flags --list-episodes, --recent-rewards, and --list-runs are available for quick checks.
  - Known limitation: the demo logs episodes/rewards only when relevant code paths execute (e.g., startEpisode/logReward). If not triggered, CLI queries may return count=0 even with a valid DB. Use --list-runs, --list-episodes=<run_id>, and --recent-rewards=<run_id,N> to verify data presence; pass --memory-db=PATH during the run to enable persistence.

Testing
- neuroforge_tests includes connectivity and Cap'n Proto round-trip tests; all currently passing.
- test_memorydb covers MemoryDB lifecycle, stats/experience insertions, reward/self-model logging, and error handling; all currently passing.
- Additional demo-loop integration tests can be added as features evolve.

Documentation Alignment
- Product Requirements, Advanced Neural Features, Technical Architecture, and Implementation Guide in .trae/documents align with the codebase: advanced learning primitives are present.
- Integration into a full autonomous agent loop, richer motivation/reward policies, and broader persistence scenarios remain future work; the reward/self-model logging infrastructure and Cap'n Proto state round-trip are now in place to support these next steps.