# NeuroForge Unified Substrate Benchmarking Guide

This guide defines a reproducible benchmarking suite for the core neural substrate and provides commands to generate figures and artifacts for papers (NeurIPS/IEEE/ICLR).

## Experiments
- Adaptive vs Fixed: Compare `--adaptive=on` vs `--adaptive=off` with identical learning rates and topology.
- Scale Sweep: Run at increasing neuron counts to verify smooth scaling of coherence and growth metrics.
- Bias Ablation: Disable `--survival-bias=off` to demonstrate the role of the affect layer on exploration/consolidation dynamics.

## Key Metrics (KPIs)
- Coherence: mean, variance, p95 over time.
- Growth Velocity: `Δ(assemblies + bindings)` per sample and total growth across the run.
- Assemblies: trend and terminal richness (final value).
- Optional: mean LR (if telemetry v2 includes it), adaptive events counters (low/high regime).

## Harness
Use the unified benchmarking harness:
```powershell
python scripts/benchmark_unified.py --exe build\neuroforge.exe --db build\phasec_mem.db --steps 1500 --plots
```

Outputs:
- `Artifacts\JSON\benchmarks\adaptive_vs_fixed\adaptive_on_summary.json`
- `Artifacts\JSON\benchmarks\adaptive_vs_fixed\adaptive_off_summary.json`
- `Artifacts\JSON\benchmarks\scale_sweep\scale_256_summary.json` (and 512)
- `Artifacts\JSON\benchmarks\bias_ablation\survival_bias_off_summary.json`
- Optional PNG plots in `Artifacts\PNG\benchmarks\...`
- Roll‑up: `Artifacts\JSON\benchmark_suite_summary.json`

## Manual Commands (if not using harness)
Run:
```powershell
& .\build\neuroforge.exe --unified-substrate=on --enable-learning --hebbian-rate=0.01 --stdp-rate=0.005 --wm-neurons=256 --phasec-neurons=256 --steps=1500 --memory-db=build\phasec_mem.db --memdb-interval=500 --adaptive=on --survival-bias=on
```
Export series and summarize:
```powershell
python tools\db_export.py --db build\phasec_mem.db --run latest --table substrate_states --out Artifacts\JSON\benchmarks\manual_run_series.json
python tools\summarize_series.py --json Artifacts\JSON\benchmarks\manual_run_series.json --out Artifacts\JSON\benchmarks\manual_run_summary.json
```

## Paper Figures
- Coherence vs Time, Growth Velocity vs Time, Assemblies vs Time — generated by the harness with `--plots`.
- Include in appendix or main figures as appropriate; use filenames from `Artifacts\PNG\benchmarks`.

## Reproducibility
- Toggle `--adaptive=on|off` and `--survival-bias=on|off` for A/B and ablations.
- Ensure learning is enabled and rates are explicit; keep `--memdb-interval` ~500–1000.
- For scale sweeps, adjust `--wm-neurons` and `--phasec-neurons` equally (256, 512, etc.).

## Troubleshooting
- Flat plots: increase `--steps`, confirm learning flags and rates; re‑export JSON.
- Empty CSV exports: latest run may not have `substrate_states`; use `db_export.py --run latest` JSON or specify a run with rows.

## Artifact Map
- JSON series per run: `Artifacts\JSON\benchmarks\<exp>\<tag>_series.json`
- Summary per run: `Artifacts\JSON\benchmarks\<exp>\<tag>_summary.json`
- Roll‑up: `Artifacts\JSON\benchmark_suite_summary.json`
- PNG figures: `Artifacts\PNG\benchmarks\<exp>\<tag>_*`

